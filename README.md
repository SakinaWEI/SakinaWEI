## 👋欢迎来到我的GitHub主页！

我是Sakina，目前在 [GLM-4.5 团队](https://z.ai/blog/glm-4.5)，正在寻找 TOP Talents 加入我们 ～
Join us! Top Talents for AGI, Global Hiring！！

About our team:
Our world-leading AI team has developed the cutting-edge large language and multimodal models and built the high-precision billion-scale knowledge graphs, the combination of which uniquely empowers us to create a powerful data- and knowledge-driven cognitive engine towards AGI. 

- Email: shuangshuang.wei@zhipuai.cn
- Wechat: SakinaWEI

**LLM Research Scientist/Engineer**

**Responsibilities:**

- Design and deploy state-of-the-art NLP/Multimodal LLM

- Research areas include, but are not limited to, efficient large language model architecture, multimodal learning, self-supervised representation learning, unified cross-task learning, dataset construction, RLHF, etc.

**Qualifications:**

- PhD/Master in Computer Science, Artificial Intelligence, or a related field.

- Solid research accumulation in natural language understanding, machine learning, deep learning, and multimodal domains.

- Excellent large model research capabilities, with a preference for those who have published high-quality papers in top conferences such as NeurIPS, ICLR, ICML, ACL, EMNLP, CVPR, JMLR, etc.

- Outstanding collaborative abilities, able to coordinate with platform, data, and other teams to complete systematic work, excellent direction planning and implementation capabilities.

**ML System Research Scientist/Engineer**

**Responsibilities:**

- Lead the creation of next-generation, high-capacity LLM platforms.

- Collaborate with software engineers to build platforms with cutting-edge models.

**Qualifications:**

- PhD/Master in Computer Science, Artificial Intelligence, or a related field.

- Have prior experience working with training and inference of large language models.

- Have experience in High performance, large-scale ML systems, GPUs, Kubernetes, Pytorch, or OS internals

- Proficiency in programming languages such as Python or C++ and a track record of working with deep learning frameworks (e.g., pytorch, deepspeed, etc.).

- Strong understanding of distributed computing framework & performance tuning and verification for training/finetuning/inference. 

- Being familiar with PEFT or MoE is a plus.

如果您对我的项目或工作有任何疑问或建议，请随时与我联系😊~
