## ğŸ‘‹æ¬¢è¿æ¥åˆ°æˆ‘çš„GitHubä¸»é¡µï¼

æˆ‘æ˜¯Sakinaï¼Œç›®å‰åœ¨ [GLM-4 å›¢é˜Ÿ](https://github.com/THUDM)ï¼Œæ­£åœ¨å¯»æ‰¾ TOP Talents åŠ å…¥æˆ‘ä»¬ ï½
Join us! Top Talents for AGI, Global Hiringï¼ï¼

About our team:
Our world-leading AI team has developed the cutting-edge large language and multimodal models and built the high-precision billion-scale knowledge graphs, the combination of which uniquely empowers us to create a powerful data- and knowledge-driven cognitive engine towards AGI. 

- GLM-4 å¤§æ¨¡å‹ç®—æ³•ç§‘å­¦å®¶/å·¥ç¨‹å¸ˆ
- CogVLM å¤šæ¨¡æ€å¤§æ¨¡å‹ç®—æ³•ç§‘å­¦å®¶/å·¥ç¨‹å¸ˆ
- CodeGeeX2 å¤§æ¨¡å‹ç®—æ³• ä»£ç æ–¹å‘
- AgentBench/AgentLM å¤§æ¨¡å‹ç®—æ³•
- TTS è¯­éŸ³ç®—æ³•
- AI Infra GLM-platformï¼Œæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ¨ç†åŠ é€Ÿï¼Œç½‘ç»œï¼ŒK8S
- AIGC AI-Native Cç«¯äº§å“ç»ç†
- å‰åç«¯ï¼Œåº•å±‚å¼€å‘ï¼ŒACMã€NOIç«èµ›é€‰æ‰‹

å…³äº ChatGLM å…³äºå¤§æ¨¡å‹ AGIï¼Œæœ‰ä»»ä½•æ„Ÿå…´è¶£çš„è¯é¢˜ï¼Œæ¬¢è¿äº¤æµï½ å¯ä»¥æˆ³æˆ‘è¯¦èŠğŸ‘‡ 
- Email: shuangshuang.wei@zhipuai.cn
- Wechat: SakinaWEI

**LLM Research Scientist/Engineer**

**Responsibilities:**

- Design and deploy state-of-the-art NLP/Multimodal LLM

- Research areas include, but are not limited to, efficient large language model architecture, multimodal learning, self-supervised representation learning, unified cross-task learning, dataset construction, RLHF, etc.

**Qualifications:**

- PhD/Master in Computer Science, Artificial Intelligence, or a related field.

- Solid research accumulation in natural language understanding, machine learning, deep learning, and multimodal domains.

- Excellent large model research capabilities, with a preference for those who have published high-quality papers in top conferences such as NeurIPS, ICLR, ICML, ACL, EMNLP, CVPR, JMLR, etc.

- Outstanding collaborative abilities, able to coordinate with platform, data, and other teams to complete systematic work, excellent direction planning and implementation capabilities.

**ML System Research Scientist/Engineer**

**Responsibilities:**

- Lead the creation of next-generation, high-capacity LLM platforms.

- Collaborate with software engineers to build platforms with cutting-edge models.

**Qualifications:**

- PhD/Master in Computer Science, Artificial Intelligence, or a related field.

- Have prior experience working with training and inference of large language models.

- Have experience in High performance, large-scale ML systems, GPUs, Kubernetes, Pytorch, or OS internals

- Proficiency in programming languages such as Python or C++ and a track record of working with deep learning frameworks (e.g., pytorch, deepspeed, etc.).

- Strong understanding of distributed computing framework & performance tuning and verification for training/finetuning/inference. 

- Being familiar with PEFT or MoE is a plus.

å¦‚æœæ‚¨å¯¹æˆ‘çš„é¡¹ç›®æˆ–å·¥ä½œæœ‰ä»»ä½•ç–‘é—®æˆ–å»ºè®®ï¼Œè¯·éšæ—¶ä¸æˆ‘è”ç³»ğŸ˜Š~
